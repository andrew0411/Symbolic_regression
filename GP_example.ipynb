{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "615c655e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "from gp.genetics import SymbolicRegressor\n",
    "from sklearn.utils.random import check_random_state\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/high.csv')\n",
    "df.set_index('Material', inplace=True)\n",
    "y = df.pop('Heat of formation')\n",
    "X = df\n",
    "x_tr, x_ts, y_tr, y_ts = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_tr = sc.fit_transform(x_tr)\n",
    "x_ts = sc.fit_transform(x_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1092 1092\n",
      "1092 85\n"
     ]
    }
   ],
   "source": [
    "print(len(x_tr), len(y_tr))\n",
    "n_sample, n_feature = x_tr.shape\n",
    "print(n_sample, n_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0     5.95      2.52912e+52        4         0.493791         0.557858     42.04s\n",
      "   1     4.30       1.5866e+10        7         0.444629          0.46779     42.80s\n",
      "   2     4.35      6.53161e+13        4         0.433749         0.497823     40.06s\n",
      "   3     3.13           930634        4          0.42533          0.41283     37.05s\n",
      "   4     3.15          134.316        4         0.414417         0.510247     33.85s\n",
      "   5     3.85           343.03        7         0.411905         0.490707     31.88s\n",
      "   6     3.93      1.11321e+08        3         0.410937         0.541316     31.20s\n",
      "   7     3.55          1.43956        3         0.408756          0.56079     28.29s\n",
      "   8     3.08          4.64096        3         0.409915          0.55044     26.25s\n",
      "   9     3.08          50.0763        3         0.409574         0.553482     23.99s\n",
      "  10     3.07          1.37906        3         0.411208         0.538899     21.09s\n",
      "  11     3.07      1.37375e+34        3         0.406793         0.498474     18.69s\n",
      "  12     3.09          11.6327        3         0.407336         0.493624     16.64s\n",
      "  13     3.09          270.027        3         0.402836         0.533798     14.11s\n",
      "  14     3.08      2.34434e+07        3         0.402837         0.533788     11.72s\n",
      "  15     3.10          3.85713        3          0.40228          0.53876      9.69s\n",
      "  16     3.06         0.865458        3         0.402658         0.535388      7.17s\n",
      "  17     3.03          702.701        3         0.403411         0.528661      4.77s\n",
      "  18     3.04         0.901732        3         0.400137         0.557891      2.37s\n",
      "  19     3.08          9.70089        3         0.402466           0.5371      0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SymbolicRegressor(max_samples=0.9, p_crossover=0.7, p_hoist_mutation=0.05,\n",
       "                  p_point_mutation=0.1, p_subtree_mutation=0.1,\n",
       "                  parsimony_coefficient=0.01, population_size=5000,\n",
       "                  random_state=42, stopping_criteria=0.01, verbose=1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_depth = (5, 8)\n",
    "gp = SymbolicRegressor(population_size=5000, generations=20, stopping_criteria=0.01,\n",
    "                       p_crossover=0.7, p_subtree_mutation=0.1, p_hoist_mutation=0.05,\n",
    "                       p_point_mutation=0.1, max_samples=0.9, verbose=1,\n",
    "                       parsimony_coefficient=0.01, random_state=42     \n",
    "                        )\n",
    "gp.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log(cos(X51))\n"
     ]
    }
   ],
   "source": [
    "print(gp._program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    12.46     5.44599e+107       10         0.642958          0.63106      1.38m\n",
      "   1     5.46      4.26411e+28        4         0.612599         0.626963      1.20m\n",
      "   2     5.07      5.33755e+46        8         0.569606         0.630061      1.14m\n",
      "   3     2.97      3.13002e+09        5         0.555984          0.53948      1.01m\n",
      "   4     2.98       3.7335e+21        5          0.54508         0.631043     56.64s\n",
      "   5     3.52          2212.73        5         0.544508         0.635435     54.30s\n",
      "   6     3.34          872.806        5         0.540494         0.530439     51.64s\n",
      "   7     3.24      3.66353e+43        5           0.5318         0.603816     50.43s\n",
      "   8     3.18           49.914        5         0.528805         0.626858     50.16s\n",
      "   9     3.20          102.724        5         0.526354         0.645013     47.66s\n",
      "  10     3.30      1.18349e+08        5         0.529379         0.622519     45.94s\n",
      "  11     3.33       3.4164e+13        5         0.528029         0.632676     44.59s\n",
      "  12     3.47      6.04795e+36        5         0.527127         0.639351     41.64s\n",
      "  13     3.59            70324        5         0.527125         0.639365     39.12s\n",
      "  14     3.82      5.15337e+10        5         0.526388         0.644766     37.81s\n",
      "  15     4.18      3.95342e+18        5         0.526729         0.642274     34.75s\n",
      "  16     4.49           327.06        5         0.523948         0.662268     32.29s\n",
      "  17     4.84           934377        5         0.521424         0.679818     30.71s\n",
      "  18     5.00          53146.2        5         0.521796         0.677267     27.56s\n",
      "  19     5.05      3.71327e+06        5         0.523129         0.668023     25.21s\n",
      "  20     5.12           409954        5         0.525423         0.651753     23.30s\n",
      "  21     5.03      3.20925e+09        5         0.522745         0.670703     20.13s\n",
      "  22     5.05       3.3415e+06        5         0.520344         0.687165     17.60s\n",
      "  23     5.05      1.34599e+07        5         0.516324         0.713725     15.10s\n",
      "  24     5.11      6.69991e+08        5         0.521682         0.678049     12.97s\n",
      "  25     5.10      6.80793e+21        5         0.521148         0.681707     10.31s\n",
      "  26     5.03           608642        5         0.515877         0.716605      7.88s\n",
      "  27     5.10      5.62986e+13        5         0.522251         0.674128      5.09s\n",
      "  28     5.05          33697.8        5         0.522362         0.673361      2.55s\n",
      "  29     5.07      9.62667e+25        5         0.520992          0.68277      0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SymbolicRegressor(generations=30, init_depth=(3, 10), max_samples=0.9,\n",
       "                  metric='rmse', p_crossover=0.7, p_hoist_mutation=0.05,\n",
       "                  p_point_mutation=0.1, p_subtree_mutation=0.1,\n",
       "                  parsimony_coefficient=0.01, population_size=5000,\n",
       "                  random_state=42, stopping_criteria=0.01, verbose=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_depth = (3, 10)\n",
    "gp = SymbolicRegressor(population_size=5000, generations=30, stopping_criteria=0.01, init_depth=init_depth,\n",
    "                       p_crossover=0.7, p_subtree_mutation=0.1, p_hoist_mutation=0.05,\n",
    "                       p_point_mutation=0.1, max_samples=0.9, verbose=1, metric='rmse',\n",
    "                       parsimony_coefficient=0.01, random_state=42     \n",
    "                        )\n",
    "gp.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg(sqrt(log(cos(X8))))\n"
     ]
    }
   ],
   "source": [
    "# Best program after final generation\n",
    "print(gp._program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5209919841758972"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best program's fitness result on training dataset\n",
    "gp._program.raw_fitness_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.54406812, -1.22226961, -0.54406812, ..., -1.22226961,\n",
       "       -0.54406812, -0.54406812])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best Program's result on training dataset\n",
    "# 추후에 target에서 빼줘서 residual을 새로운 target으로 생성\n",
    "\n",
    "gp._program.execute(x_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get program's depth\n",
    "\n",
    "gp._program._depth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5709919841758972"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp._program.fitness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.54406812, -1.22226961, -0.54406812, ..., -1.22226961,\n",
       "       -0.54406812, -0.54406812])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best program's result on training dataset\n",
    "# Above code 'gp._prgoram.execute(x_tr) 과 동일한 결과\n",
    "gp.predict(x_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training : 0.3353671779562626, Test : 0.27172870472316923\n",
      "Training : 0.3353671779562626, Test : 0.27172870472316923\n"
     ]
    }
   ],
   "source": [
    "# R square 값 구하기\n",
    "# sklearn.metrics.r2_score과 동일\n",
    "tr_score = gp.score(x_tr, y_tr)\n",
    "ts_score = gp.score(x_ts, y_ts)\n",
    "print(f'Training : {tr_score}, Test : {ts_score}')\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "tr_score = r2_score(y_tr, gp.predict(x_tr))\n",
    "ts_score = r2_score(y_ts, gp.predict(x_ts))\n",
    "print(f'Training : {tr_score}, Test : {ts_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'method': 'Crossover',\n",
       " 'parent_idx': 853,\n",
       " 'parent_nodes': range(1, 5),\n",
       " 'donor_idx': 2195,\n",
       " 'donor_nodes': [0]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best program 이 생성된 history\n",
    "gp._program.parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    12.46     5.44599e+107        6         0.541839         0.557822      1.40m\n",
      "   1     4.38      3.03365e+73        6         0.532801         0.630768      1.12m\n",
      "   2     3.03      5.33755e+46        7         0.531597         0.587107      1.02m\n",
      "   3     3.04          40.4044        6         0.528107         0.614583      1.03m\n",
      "   4     3.25       3.7335e+21        3         0.530139         0.674328     57.66s\n",
      "   5     3.19          1108.31        4         0.528582         0.635148     55.77s\n",
      "   6     3.21          46.6257        3         0.527236         0.694348     57.65s\n",
      "   7     3.20          63643.5        3         0.525786         0.675393     54.47s\n",
      "   8     3.16          6.22832        3         0.527718         0.661802     52.56s\n",
      "   9     3.14          85.1564        3         0.525652         0.676322     51.65s\n",
      "  10     3.19      1.18349e+08        3         0.526533         0.670176     47.55s\n",
      "  11     3.15       3.4164e+13        3         0.526732         0.648722     45.20s\n",
      "  12     3.18      6.04795e+36        3          0.52611         0.653214     42.71s\n",
      "  13     3.18          70323.7        3          0.52503         0.660925     41.77s\n",
      "  14     3.18      5.15337e+10        3         0.525059         0.660722     37.89s\n",
      "  15     3.20      3.95342e+18        3         0.525113          0.66034     35.50s\n",
      "  16     3.14          326.663        3         0.526746         0.648619     33.00s\n",
      "  17     3.18           934376        3         0.522852         0.676167     31.38s\n",
      "  18     3.18          53145.9        3         0.519188         0.700916     27.82s\n",
      "  19     3.20      3.71327e+06        3         0.526467         0.650638     25.41s\n",
      "  20     3.22          4339.13        3         0.526085         0.653394     23.66s\n",
      "  21     3.18      3.20925e+09        3          0.52542         0.658154     20.24s\n",
      "  22     3.18      3.34149e+06        3         0.525172         0.659916     17.80s\n",
      "  23     3.19          2.83891        3          0.51767          0.71087     15.79s\n",
      "  24     3.20           118261        3         0.525476         0.657754     12.68s\n",
      "  25     3.23      6.80793e+21        3         0.526686         0.649057     10.17s\n",
      "  26     3.15           608641        3         0.524687         0.663351      7.61s\n",
      "  27     3.22      5.62985e+13        3         0.526252         0.652195      5.30s\n",
      "  28     3.19          33691.1        3         0.525912         0.654634      2.55s\n",
      "  29     3.19      9.62667e+25        3         0.525257         0.659313      0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SymbolicRegressor(generations=30, init_depth=(3, 10), max_samples=0.9,\n",
       "                  metric='rmse', p_crossover=0.7, p_hoist_mutation=0.05,\n",
       "                  p_point_mutation=0.1, p_subtree_mutation=0.1,\n",
       "                  parsimony_coefficient=0.01, population_size=5000,\n",
       "                  random_state=42, stopping_criteria=0.01, verbose=1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr = y_tr - gp.predict(x_tr)\n",
    "y_ts = y_ts - gp.predict(x_ts)\n",
    "\n",
    "init_depth = (3, 10)\n",
    "gp = SymbolicRegressor(population_size=5000, generations=30, stopping_criteria=0.01, init_depth=init_depth,\n",
    "                       p_crossover=0.7, p_subtree_mutation=0.1, p_hoist_mutation=0.05,\n",
    "                       p_point_mutation=0.1, max_samples=0.9, verbose=1, metric='rmse',\n",
    "                       parsimony_coefficient=0.01, random_state=42     \n",
    "                        )\n",
    "gp.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sin(pow2(X8))\n"
     ]
    }
   ],
   "source": [
    "# Best program after final generation\n",
    "print(gp._program)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "67c0ceae142a0845df9ad1b93ebe656f16c2103af5b17815984fb51155e66b4e"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('pytorch': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
