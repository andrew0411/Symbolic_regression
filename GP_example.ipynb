{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "615c655e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "from gp.genetics import SymbolicRegressor\n",
    "from sklearn.utils.random import check_random_state\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/high.csv')\n",
    "df.set_index('Material', inplace=True)\n",
    "y = df.pop('Heat of formation')\n",
    "X = df\n",
    "x_tr, x_ts, y_tr, y_ts = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_tr = sc.fit_transform(x_tr)\n",
    "x_ts = sc.fit_transform(x_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1092 1092\n",
      "1092 85\n"
     ]
    }
   ],
   "source": [
    "print(len(x_tr), len(y_tr))\n",
    "n_sample, n_feature = x_tr.shape\n",
    "print(n_sample, n_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    25.43          5146.19        3         0.467756         0.450665     53.42s\n",
      "   1     3.51          1.50625        3         0.455547         0.559657     38.81s\n",
      "   2     3.15           1.4176        3          0.45042         0.605428     37.63s\n",
      "   3     2.91         0.996109        3         0.448346         0.623941     34.52s\n",
      "   4     3.26          73.3247        3         0.444151         0.661393     31.85s\n",
      "   5     3.16          0.96215        5         0.441367          0.40033     30.19s\n",
      "   6     3.20          0.96353        5         0.431917          0.48469     27.62s\n",
      "   7     3.20          6.77462        5          0.43127         0.490467     25.51s\n",
      "   8     3.22          1.13984        5         0.430558         0.496826     24.00s\n",
      "   9     3.22          1.20989        5         0.427268          0.52619     21.34s\n",
      "  10     3.47          1.40105        5         0.427461         0.524474     19.35s\n",
      "  11     4.04          2.51449        5         0.419455         0.411963     17.96s\n",
      "  12     4.85           1.2874        5         0.412753          0.47179     15.67s\n",
      "  13     5.05          1.07643        5           0.4062         0.530286     13.54s\n",
      "  14     5.08          1.00026        5         0.405019         0.540832     11.55s\n",
      "  15     5.17          26.2981        5         0.401622         0.571159      9.03s\n",
      "  16     5.00           1.0474        5         0.400887         0.577719      6.75s\n",
      "  17     5.14          1.81155        5         0.401962         0.568121      4.63s\n",
      "  18     5.04          4.83797        5         0.402636          0.56211      2.27s\n",
      "  19     5.19          2.31994        5         0.401254         0.574448      0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SymbolicRegressor(max_samples=0.9, p_crossover=0.7, p_hoist_mutation=0.05,\n",
       "                  p_point_mutation=0.1, p_subtree_mutation=0.1,\n",
       "                  parsimony_coefficient=0.01, population_size=5000,\n",
       "                  random_state=42, stopping_criteria=0.01, verbose=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp = SymbolicRegressor(population_size=5000, generations=20, stopping_criteria=0.01,\n",
    "                       p_crossover=0.7, p_subtree_mutation=0.1, p_hoist_mutation=0.05,\n",
    "                       p_point_mutation=0.1, max_samples=0.9, verbose=1,\n",
    "                       parsimony_coefficient=0.01, random_state=42     \n",
    "                        )\n",
    "gp.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mul(mul(X8, -0.685), X8)\n"
     ]
    }
   ],
   "source": [
    "print(gp._program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    25.43           121090        3         0.683159         0.602846     54.61s\n",
      "   1     3.45          4.54564        3         0.642922         0.916382     38.80s\n",
      "   2     3.21          5.15017        3         0.648327         0.881735     37.03s\n",
      "   3     2.27          3.03607        3         0.613507         0.496964     35.79s\n",
      "   4     1.47          607.148        3         0.594459         0.672589     32.32s\n",
      "   5     1.57          2.85059        3          0.58498         0.743091     30.09s\n",
      "   6     2.96          2.72085        3         0.582418         0.760844     29.26s\n",
      "   7     3.19          67.0386        3         0.582691         0.758974     25.57s\n",
      "   8     3.21          3.66517        3         0.576934         0.797271     23.31s\n",
      "   9     3.16          4.10314        3         0.581429         0.767565     22.30s\n",
      "  10     3.25          6.66712        3         0.582138         0.762757     19.14s\n",
      "  11     3.27          16.5516        3         0.581033         0.770239     17.27s\n",
      "  12     3.23          4.71674        3         0.577436         0.794022     15.87s\n",
      "  13     3.19          3.20994        3         0.581565         0.766649     12.83s\n",
      "  14     3.19          2.39362        3         0.580468         0.774032     10.78s\n",
      "  15     3.26          498.378        3         0.580802         0.771791      8.85s\n",
      "  16     3.12          2.68389        3         0.582396         0.760996      6.39s\n",
      "  17     3.27          20.2679        3         0.578588         0.786498      4.29s\n",
      "  18     3.17          46.6374        3         0.583053         0.756488      2.14s\n",
      "  19     3.30          10.5423        3         0.582497         0.760307      0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SymbolicRegressor(max_samples=0.9, metric='rmse', p_crossover=0.7,\n",
       "                  p_hoist_mutation=0.05, p_point_mutation=0.1,\n",
       "                  p_subtree_mutation=0.1, parsimony_coefficient=0.01,\n",
       "                  population_size=5000, random_state=42, stopping_criteria=0.01,\n",
       "                  verbose=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp = SymbolicRegressor(population_size=5000, generations=20, stopping_criteria=0.01,\n",
    "                       p_crossover=0.7, p_subtree_mutation=0.1, p_hoist_mutation=0.05,\n",
    "                       p_point_mutation=0.1, max_samples=0.9, verbose=1, metric='rmse',\n",
    "                       parsimony_coefficient=0.01, random_state=42     \n",
    "                        )\n",
    "gp.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mul(X52, X51)\n"
     ]
    }
   ],
   "source": [
    "# Best program after final generation\n",
    "print(gp._program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5824967699992059"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best program's fitness result on training dataset\n",
    "gp._program.raw_fitness_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.5945983 , -1.59203403, -0.5945983 , ..., -1.59203403,\n",
       "       -1.59203403, -0.5945983 ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best Program's result on training dataset\n",
    "# 추후에 target에서 빼줘서 residual을 새로운 target으로 생성\n",
    "\n",
    "gp._program.execute(x_tr)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "67c0ceae142a0845df9ad1b93ebe656f16c2103af5b17815984fb51155e66b4e"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('pytorch': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
